{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "130f5017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\J'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\J'\n",
      "C:\\Users\\wengqc\\AppData\\Local\\Temp\\ipykernel_16060\\2232878236.py:5: SyntaxWarning: invalid escape sequence '\\J'\n",
      "  notebook_dir = \"CASA0004\\JSON_interselect_homiocide_count.ipynb\"\n"
     ]
    }
   ],
   "source": [
    "# ========= Cell 1: 填写任务信息 =========\n",
    "task_name = \"match_point_barrio\"\n",
    "dataset = \"Bogota_points\"\n",
    "code_version = \"v1.0\"\n",
    "notebook_dir = \"CASA0004\\JSON_interselect_homiocide_count.ipynb\"\n",
    "input_dir = r\"E:\\Dissertation\\XGBoost_cleaning\\2016south_Mask2Former_with_geo_batched\"     # 输入文件夹\n",
    "output_dir = r\"E:/Dissertation/XGBoost_cleaning/2016south_Mask2Former_with_geobarrio\"   # 输出文件夹\n",
    "note = \"匹配Barrios社区+UPZ\"\n",
    "barrios_file = \"E:/Dissertation/XGBoost_cleaning/Barrios_will_UPZ.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23c40bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Cell 2: 批处理逻辑 =========\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import fiona\n",
    "from shapely.geometry import shape, Point\n",
    "from pathlib import Path\n",
    "\n",
    "def batch_match_points(input_dir, output_dir, barrios_file, batch_size=200):\n",
    "    start_time = time.time()\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 读取社区边界\n",
    "    barrios = []\n",
    "    with fiona.open(barrios_file, \"r\") as src:\n",
    "        for feat in src:\n",
    "            geom = shape(feat[\"geometry\"])\n",
    "            props = feat[\"properties\"]\n",
    "            barrios.append((geom, props[\"barriocomu\"], props[\"codigo_upz\"]))\n",
    "\n",
    "    # 递归筛选 point 文件\n",
    "    input_dir = Path(input_dir)\n",
    "    all_files = [f for f in input_dir.rglob(\"*.json\") if \"point\" in f.name]\n",
    "    all_files.sort()\n",
    "\n",
    "    batch_index = 1\n",
    "    for i in range(0, len(all_files), batch_size):\n",
    "        batch_files = all_files[i:i+batch_size]\n",
    "        batch_folder = Path(output_dir) / f\"batch_{batch_index:03d}\"\n",
    "        batch_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for file_path in batch_files:\n",
    "            filename = file_path.name\n",
    "            try:\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ 跳过坏文件: {file_path}, 错误: {e}\")\n",
    "                continue\n",
    "\n",
    "            lon, lat = data.get(\"longitude\"), data.get(\"latitude\")\n",
    "            if lon is None or lat is None:\n",
    "                print(f\"⚠️ 文件缺少经纬度: {file_path}\")\n",
    "                continue\n",
    "\n",
    "            point = Point(lon, lat)\n",
    "\n",
    "            barrio_name, upz_code = None, None\n",
    "            for geom, bname, upz in barrios:\n",
    "                if geom.contains(point):\n",
    "                    barrio_name = bname\n",
    "                    upz_code = upz\n",
    "                    break\n",
    "\n",
    "            data[\"barrio\"] = barrio_name\n",
    "            data[\"upz_code\"] = upz_code\n",
    "\n",
    "            out_path = batch_folder / filename\n",
    "            with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"完成 batch {batch_index:03d}，文件数 {len(batch_files)}\")\n",
    "        batch_index += 1\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    return duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bc15759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成 batch 001，文件数 200\n",
      "完成 batch 002，文件数 200\n",
      "完成 batch 003，文件数 200\n",
      "完成 batch 004，文件数 200\n",
      "完成 batch 005，文件数 200\n",
      "完成 batch 006，文件数 200\n",
      "完成 batch 007，文件数 200\n",
      "完成 batch 008，文件数 200\n",
      "完成 batch 009，文件数 200\n",
      "完成 batch 010，文件数 200\n",
      "完成 batch 011，文件数 200\n",
      "完成 batch 012，文件数 200\n",
      "完成 batch 013，文件数 200\n",
      "完成 batch 014，文件数 200\n",
      "完成 batch 015，文件数 200\n",
      "完成 batch 016，文件数 200\n",
      "完成 batch 017，文件数 200\n",
      "完成 batch 018，文件数 200\n",
      "完成 batch 019，文件数 200\n",
      "完成 batch 020，文件数 200\n",
      "完成 batch 021，文件数 200\n",
      "完成 batch 022，文件数 200\n",
      "完成 batch 023，文件数 200\n",
      "完成 batch 024，文件数 200\n",
      "完成 batch 025，文件数 200\n",
      "完成 batch 026，文件数 200\n",
      "完成 batch 027，文件数 200\n",
      "完成 batch 028，文件数 200\n",
      "完成 batch 029，文件数 200\n",
      "完成 batch 030，文件数 200\n",
      "完成 batch 031，文件数 200\n",
      "完成 batch 032，文件数 200\n",
      "完成 batch 033，文件数 200\n",
      "完成 batch 034，文件数 200\n",
      "完成 batch 035，文件数 200\n",
      "完成 batch 036，文件数 200\n",
      "完成 batch 037，文件数 200\n",
      "完成 batch 038，文件数 200\n",
      "完成 batch 039，文件数 200\n",
      "完成 batch 040，文件数 200\n",
      "完成 batch 041，文件数 200\n",
      "完成 batch 042，文件数 200\n",
      "完成 batch 043，文件数 200\n",
      "完成 batch 044，文件数 200\n",
      "完成 batch 045，文件数 200\n",
      "完成 batch 046，文件数 200\n",
      "完成 batch 047，文件数 200\n",
      "完成 batch 048，文件数 200\n",
      "完成 batch 049，文件数 200\n",
      "完成 batch 050，文件数 200\n",
      "完成 batch 051，文件数 200\n",
      "完成 batch 052，文件数 200\n",
      "完成 batch 053，文件数 200\n",
      "完成 batch 054，文件数 200\n",
      "完成 batch 055，文件数 200\n",
      "完成 batch 056，文件数 200\n",
      "完成 batch 057，文件数 200\n",
      "完成 batch 058，文件数 200\n",
      "完成 batch 059，文件数 200\n",
      "完成 batch 060，文件数 200\n",
      "完成 batch 061，文件数 200\n",
      "完成 batch 062，文件数 200\n",
      "完成 batch 063，文件数 200\n",
      "完成 batch 064，文件数 200\n",
      "完成 batch 065，文件数 200\n",
      "完成 batch 066，文件数 200\n",
      "完成 batch 067，文件数 200\n",
      "完成 batch 068，文件数 200\n",
      "完成 batch 069，文件数 200\n",
      "完成 batch 070，文件数 200\n",
      "完成 batch 071，文件数 200\n",
      "完成 batch 072，文件数 200\n",
      "完成 batch 073，文件数 200\n",
      "完成 batch 074，文件数 200\n",
      "完成 batch 075，文件数 200\n",
      "完成 batch 076，文件数 200\n",
      "完成 batch 077，文件数 200\n",
      "完成 batch 078，文件数 200\n",
      "完成 batch 079，文件数 200\n",
      "完成 batch 080，文件数 200\n",
      "完成 batch 081，文件数 200\n",
      "完成 batch 082，文件数 200\n",
      "完成 batch 083，文件数 200\n",
      "完成 batch 084，文件数 200\n",
      "完成 batch 085，文件数 200\n",
      "完成 batch 086，文件数 200\n",
      "完成 batch 087，文件数 200\n",
      "完成 batch 088，文件数 200\n",
      "完成 batch 089，文件数 200\n",
      "完成 batch 090，文件数 200\n",
      "完成 batch 091，文件数 200\n",
      "完成 batch 092，文件数 200\n",
      "完成 batch 093，文件数 200\n",
      "完成 batch 094，文件数 200\n",
      "完成 batch 095，文件数 200\n",
      "完成 batch 096，文件数 200\n",
      "完成 batch 097，文件数 200\n",
      "完成 batch 098，文件数 200\n",
      "完成 batch 099，文件数 200\n",
      "完成 batch 100，文件数 200\n",
      "完成 batch 101，文件数 200\n",
      "完成 batch 102，文件数 200\n",
      "完成 batch 103，文件数 200\n",
      "完成 batch 104，文件数 200\n",
      "完成 batch 105，文件数 200\n",
      "完成 batch 106，文件数 200\n",
      "完成 batch 107，文件数 200\n",
      "完成 batch 108，文件数 200\n",
      "完成 batch 109，文件数 200\n",
      "完成 batch 110，文件数 200\n",
      "完成 batch 111，文件数 200\n",
      "完成 batch 112，文件数 200\n",
      "完成 batch 113，文件数 200\n",
      "完成 batch 114，文件数 200\n",
      "完成 batch 115，文件数 200\n",
      "完成 batch 116，文件数 200\n",
      "完成 batch 117，文件数 200\n",
      "完成 batch 118，文件数 200\n",
      "完成 batch 119，文件数 200\n",
      "完成 batch 120，文件数 200\n",
      "完成 batch 121，文件数 200\n",
      "完成 batch 122，文件数 200\n",
      "完成 batch 123，文件数 200\n",
      "完成 batch 124，文件数 200\n",
      "完成 batch 125，文件数 200\n",
      "完成 batch 126，文件数 200\n",
      "完成 batch 127，文件数 200\n",
      "完成 batch 128，文件数 200\n",
      "完成 batch 129，文件数 200\n",
      "完成 batch 130，文件数 200\n",
      "完成 batch 131，文件数 200\n",
      "完成 batch 132，文件数 200\n",
      "完成 batch 133，文件数 200\n",
      "完成 batch 134，文件数 200\n",
      "完成 batch 135，文件数 200\n",
      "完成 batch 136，文件数 200\n",
      "完成 batch 137，文件数 200\n",
      "完成 batch 138，文件数 200\n",
      "完成 batch 139，文件数 200\n",
      "完成 batch 140，文件数 200\n",
      "完成 batch 141，文件数 200\n",
      "完成 batch 142，文件数 200\n",
      "完成 batch 143，文件数 200\n",
      "完成 batch 144，文件数 200\n",
      "完成 batch 145，文件数 200\n",
      "完成 batch 146，文件数 200\n",
      "完成 batch 147，文件数 200\n",
      "完成 batch 148，文件数 200\n",
      "完成 batch 149，文件数 200\n",
      "完成 batch 150，文件数 200\n",
      "完成 batch 151，文件数 200\n",
      "完成 batch 152，文件数 200\n",
      "完成 batch 153，文件数 200\n",
      "完成 batch 154，文件数 200\n",
      "完成 batch 155，文件数 200\n",
      "完成 batch 156，文件数 200\n",
      "完成 batch 157，文件数 200\n",
      "完成 batch 158，文件数 170\n",
      "任务完成，用时 994.94 秒，日志已记录。\n"
     ]
    }
   ],
   "source": [
    "# ========= Cell 3: 写日志 =========\n",
    "def append_log(task_name, dataset, code_version, input_dir, output_dir, status, duration, note):\n",
    "    log_line = f\"{task_name},{dataset},{code_version},{input_dir},{output_dir},{status},{duration:.2f},{note}\\n\"\n",
    "    with open(\"task_log.csv\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(log_line)\n",
    "\n",
    "duration = batch_match_points(input_dir, output_dir, barrios_file, batch_size=200)\n",
    "append_log(task_name, dataset, code_version, input_dir, output_dir, \"done\", duration, note)\n",
    "print(f\"任务完成，用时 {duration:.2f} 秒，日志已记录。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e1ca2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 日志写入完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\wengqc\\AppData\\Local\\Temp\\ipykernel_12392\\4049532167.py:3: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  repo_dir = 'E:\\Dissertation\\CASA0004'\n"
     ]
    }
   ],
   "source": [
    "# ===== 记录日志 =====\n",
    "def append_log(task_name, dataset, code_version, input_dir, output_dir, status, duration, note):\n",
    "    repo_dir = 'E:\\Dissertation\\CASA0004'\n",
    "    log_path = f\"{repo_dir}/operation_log.md\"\n",
    "\n",
    "    # 写入日志\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"**任务名称**: {task_name}\\n\")\n",
    "        f.write(f\"**数据集**: {dataset}\\n\")\n",
    "        f.write(f\"**代码版本**: {code_version}\\n\")\n",
    "        f.write(f\"**输入目录**: {input_dir}\\n\")\n",
    "        f.write(f\"**输出目录**: {output_dir}\\n\")\n",
    "        f.write(f\"**状态**: {status}\\n\")\n",
    "        f.write(f\"**耗时**: {duration}\\n\")\n",
    "        f.write(f\"**备注**: {note}\\n\\n\")\n",
    "\n",
    "    print(\"✅ 日志写入完成\")\n",
    "status=\"finished\"\n",
    "append_log(task_name, dataset, code_version, input_dir, output_dir, status, duration, note)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
